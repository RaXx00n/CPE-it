
## <b> CPEit - Common Platform Enumeration Inventory Tools - 2023 CSI Project</b>


CPEit consists of two components under development:

  *An Agent containing scripts that gather information on the software installed on a machine from multiple system sourcs,
  makes an educated guess on potential CPEs, and prepares them for ingestion into Elastic.
  
  *An ELK stack configured for taking the JSON data generated by the Agent and fuzzy string-matching NIST's Official CPE Dictionary for it,
  allowing an administrator to quickly build an inventory of CPEs for all installed software on their environment, and keep it up to date automatically
  by setting the Agent to run on intervals and Elastic to generate alerts.
  
  
### <b>Install the ELK Stack</b>

1. Run the self-installer that will install Elasticsearch, Logstash, and Kibana with the CPEit configurations.

<code>sudo bash cpeit-elk/Install.sh </code>

2. Start logstash with:

<code>/usr/share/logstash/bin/logstash -f /usr/share/logstash/logstash.conf --path.settings /etc/logstash</code>

3. Note the password generated from running:

 <code>/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic</code>
 
4. Copy and paste the password into the password fields in /usr/share/logstash/logstash.conf
 
5. Note the enrollment token generated from the command below:
 
 <code>/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana</code>
 
 6. Navigate to http://127.0.0.1:5601 and paste this token in.
 
 7. Run the command below for the Kibana verification code and paste it back into the browser:
 
<code>sudo /usr/share/kibana/bin/kibana-verification-code</code>

8. Now all three components of the stack should be working and connected to each other and ingesting the default path set in logstash.conf. By default it is:
/home/kali/Desktop/testdata.ndjson

[testdata.ndjson](https://github.com/RaXx00n/cpeit/blob/main/cpeit-elk/testdata.ndjson) has been included for testing!

9. In order to ingest your own data, you will need to configure senddata.py in the agent's files to one of the Logstash pipelines.

By default the pipeline inputs are: 

path => "/home/kali/Desktop/official_cpe_dictionary_v2.3.xml"

^ Download the CPE Dictionary from the NVD website and place it here to ingest the CPE dictionary for faster, offline searching using Elasticsearch. This can take some time to build as there will be over one million records.

path => "/home/kali/Desktop/testdata.ndjson"

^ This is the data including for testing.

port => 5000

^ This is where to point your senddata.py or other scripts to for ingesting Got-Combined.json
